{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import time\n",
    "import gdown\n",
    "import pandas as pd\n",
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=13ZePGua4XOzuTxI9omH5QnhOpt0LPRLc\n",
      "To: c:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\file.csv\n",
      "100%|██████████| 21.4M/21.4M [00:08<00:00, 2.55MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Results:\n",
      "             Model  Training Time (s)  Accuracy  F1-score  Precision    Recall\n",
      "0  Log. Regression           4.033404  0.876957  0.819468   0.769053  0.876957\n",
      "1      Naive Bayes           1.279230  0.518574  0.599483   0.788506  0.518574\n",
      "2    Random Forest           4.955732  0.876957  0.819468   0.769053  0.876957\n"
     ]
    }
   ],
   "source": [
    "# URL berbagi dari Google Drive\n",
    "url = 'https://drive.google.com/uc?id=13ZePGua4XOzuTxI9omH5QnhOpt0LPRLc'\n",
    "output = 'file.csv'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "file_path = 'file.csv'\n",
    "\n",
    "# Inisialisasi Spark session\n",
    "spark = SparkSession.builder.appName(\"InsuranceClassification\").getOrCreate()\n",
    "\n",
    "\n",
    "# Memuat dataset\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Menyiapkan fitur dan label\n",
    "feature_columns = df.columns[:-1]  # Asumsikan kolom terakhir adalah label\n",
    "label_column = df.columns[-1]\n",
    "\n",
    "# Mengonversi kolom string menjadi indeks numerik\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column + \"_index\").fit(df)\n",
    "    for column in feature_columns if dict(df.dtypes)[column] == 'string'\n",
    "]\n",
    "\n",
    "for indexer in indexers:\n",
    "    df = indexer.transform(df)\n",
    "\n",
    "# Menyiapkan kolom fitur yang baru\n",
    "indexed_feature_columns = [\n",
    "    column + \"_index\" if dict(df.dtypes)[column] == 'string' else column\n",
    "    for column in feature_columns\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=indexed_feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(df).select(\"features\", col(label_column).alias(\"label\"))\n",
    "\n",
    "# Mengonversi label menjadi indeks numerik\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "data = label_indexer.transform(data).select(\"features\", \"indexedLabel\")\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Inisialisasi evaluator\n",
    "#evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Inisialisasi model Logistic Regression\n",
    "lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Inisialisasi model Naive Bayes\n",
    "nb = NaiveBayes(labelCol=\"indexedLabel\", featuresCol=\"features\")\n",
    "\n",
    "# Inisialisasi model Random Forest\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "# List untuk menyimpan hasil dari masing-masing model\n",
    "results = []\n",
    "\n",
    "# Definisikan fungsi untuk melatih dan mengevaluasi model\n",
    "def train_and_evaluate(model, model_name):\n",
    "    start_time = time.time()\n",
    "    trained_model = model.fit(train_data)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluasi menggunakan MulticlassClassificationEvaluator\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\")\n",
    "    predictions = trained_model.transform(test_data)\n",
    "    \n",
    "    # Menghitung metrik evaluasi\n",
    "    accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "    f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "    precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "    recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "    \n",
    "    # Menambahkan hasil ke dalam list results\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Training Time (s)\": training_time,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-score\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\" : recall\n",
    "    })\n",
    "    \n",
    "    # Print classification report\n",
    "    #print(f\"Classification Report for {model_name}:\")\n",
    "    #predictions.select(\"indexedLabel\", \"prediction\").show()\n",
    "\n",
    "# Train dan evaluasi masing-masing model\n",
    "train_and_evaluate(lr, \"Log. Regression\")\n",
    "train_and_evaluate(nb, \"Naive Bayes\")\n",
    "train_and_evaluate(rf, \"Random Forest\")\n",
    "\n",
    "# Menampilkan hasil akhir\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Menutup SparkSession\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = nb.fit(train_data)\n",
    "model_path = \"naive_bayes_model\"\n",
    "nb_model.write().overwrite().save(model_path)\n",
    "\n",
    "#model export\n",
    "#with open('modelNB.pkl','wb') as file:\n",
    "    #pickle.dump(modelNB, file)\n",
    "# Menutup SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
